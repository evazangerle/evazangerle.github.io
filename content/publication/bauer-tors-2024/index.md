---
title: 'Exploring the Landscape of Recommender Systems Evaluation: Practices and Perspectives'
authors:
- Christine Bauer
- Eva Zangerle
- Alan Said
date: '2024-03-01'
publishDate: '2024-03-18T19:21:08.062582Z'
publication_types:
- article-journal
publication: '*ACM Transactions on Recommender Systems*'
doi: 10.1145/3629170
abstract: Recommender systems research and practice are fast-developing topics with
  growing adoption in a wide variety of information access scenarios. In this article,
  we present an overview of research specifically focused on the evaluation of recommender
  systems. We perform a systematic literature review, in which we analyze 57 papers
  spanning six years (2017–2022). Focusing on the processes surrounding evaluation,
  we dial in on the methods applied, the datasets utilized, and the metrics used.
  Our study shows that the predominant experiment type in research on the evaluation
  of recommender systems is offline experimentation and that online evaluations are
  primarily used in combination with other experimentation methods, e.g., an offline
  experiment. Furthermore, we find that only a few datasets (MovieLens, Amazon review
  dataset) are widely used, while many datasets are used in only a few papers each.
  We observe a similar scenario when analyzing the employed performance metrics—a
  few metrics are widely used (precision, normalized Discounted Cumulative Gain, and
  Recall), while many others are used in only a few papers. Overall, our review indicates
  that beyond-accuracy qualities are rarely assessed. Our analysis shows that the
  research community working on evaluation has focused on the development of evaluation
  in a rather narrow scope, with the majority of experiments focusing on a few metrics,
  datasets, and methods.
tags:
- Evaluation
- survey
- systematic literature review
- recommender systems
links:
- name: URL
  url: https://doi.org/10.1145/3629170
---
